{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx4xB_NDECLY",
        "outputId": "45003678-7175-4c74-f968-2616833cbdea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.19.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.08MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cuda\n",
            "Epoch 1, Batch 100, Loss: 0.5739\n",
            "Epoch 1, Batch 200, Loss: 0.1660\n",
            "Epoch 1, Batch 300, Loss: 0.1477\n",
            "Epoch 1, Batch 400, Loss: 0.1094\n",
            "Epoch 1, Batch 500, Loss: 0.0894\n",
            "Epoch 1, Batch 600, Loss: 0.0812\n",
            "Epoch 1, Batch 700, Loss: 0.0831\n",
            "Epoch 1, Batch 800, Loss: 0.0791\n",
            "Epoch 1, Batch 900, Loss: 0.0681\n",
            "Epoch 1 Accuracy: 98.50%\n",
            "Epoch 2, Batch 100, Loss: 0.0473\n",
            "Epoch 2, Batch 200, Loss: 0.0546\n",
            "Epoch 2, Batch 300, Loss: 0.0517\n",
            "Epoch 2, Batch 400, Loss: 0.0600\n",
            "Epoch 2, Batch 500, Loss: 0.0512\n",
            "Epoch 2, Batch 600, Loss: 0.0571\n",
            "Epoch 2, Batch 700, Loss: 0.0418\n",
            "Epoch 2, Batch 800, Loss: 0.0545\n",
            "Epoch 2, Batch 900, Loss: 0.0478\n",
            "Epoch 2 Accuracy: 98.97%\n",
            "Epoch 3, Batch 100, Loss: 0.0424\n",
            "Epoch 3, Batch 200, Loss: 0.0372\n",
            "Epoch 3, Batch 300, Loss: 0.0441\n",
            "Epoch 3, Batch 400, Loss: 0.0348\n",
            "Epoch 3, Batch 500, Loss: 0.0393\n",
            "Epoch 3, Batch 600, Loss: 0.0367\n",
            "Epoch 3, Batch 700, Loss: 0.0399\n",
            "Epoch 3, Batch 800, Loss: 0.0353\n",
            "Epoch 3, Batch 900, Loss: 0.0361\n",
            "Epoch 3 Accuracy: 98.94%\n",
            "Epoch 4, Batch 100, Loss: 0.0253\n",
            "Epoch 4, Batch 200, Loss: 0.0254\n",
            "Epoch 4, Batch 300, Loss: 0.0343\n",
            "Epoch 4, Batch 400, Loss: 0.0309\n",
            "Epoch 4, Batch 500, Loss: 0.0246\n",
            "Epoch 4, Batch 600, Loss: 0.0279\n",
            "Epoch 4, Batch 700, Loss: 0.0214\n",
            "Epoch 4, Batch 800, Loss: 0.0305\n",
            "Epoch 4, Batch 900, Loss: 0.0304\n",
            "Epoch 4 Accuracy: 99.05%\n",
            "Epoch 5, Batch 100, Loss: 0.0226\n",
            "Epoch 5, Batch 200, Loss: 0.0196\n",
            "Epoch 5, Batch 300, Loss: 0.0223\n",
            "Epoch 5, Batch 400, Loss: 0.0215\n",
            "Epoch 5, Batch 500, Loss: 0.0272\n",
            "Epoch 5, Batch 600, Loss: 0.0252\n",
            "Epoch 5, Batch 700, Loss: 0.0229\n",
            "Epoch 5, Batch 800, Loss: 0.0296\n",
            "Epoch 5, Batch 900, Loss: 0.0210\n",
            "Epoch 5 Accuracy: 99.12%\n",
            "Training complete!\n",
            "Model exported as mnist_model.onnx\n",
            "Download this file from Colab (left panel > Files)\n",
            "Model also saved as mnist_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2121619413.py:112: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample predictions: [7 2 1 0 4]\n",
            "Actual labels: [7 2 1 0 4]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Step 1: Train MNIST Model and Export for Web Use\n",
        "Run this in Google Colab\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision onnx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define a simple but effective CNN model\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv block 1\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Conv block 2\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "\n",
        "        # FC layers\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 2. Prepare data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# 3. Train the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MNISTNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    print(f'Epoch {epoch+1} Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 4. Export model for web use (ONNX format)\n",
        "model.eval()\n",
        "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    \"mnist_model.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    do_constant_folding=True,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
        ")\n",
        "\n",
        "print(\"Model exported as mnist_model.onnx\")\n",
        "print(\"Download this file from Colab (left panel > Files)\")\n",
        "\n",
        "# 5. Also save as PyTorch format (backup)\n",
        "torch.save(model.state_dict(), 'mnist_model.pth')\n",
        "print(\"Model also saved as mnist_model.pth\")\n",
        "\n",
        "# Test the model with a sample\n",
        "test_data, test_target = next(iter(test_loader))\n",
        "test_data = test_data[:5].to(device)\n",
        "with torch.no_grad():\n",
        "    predictions = model(test_data)\n",
        "    predicted_classes = torch.argmax(predictions, dim=1)\n",
        "    print(f\"\\nSample predictions: {predicted_classes.cpu().numpy()}\")\n",
        "    print(f\"Actual labels: {test_target[:5].numpy()}\")"
      ]
    }
  ]
}